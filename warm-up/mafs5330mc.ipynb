{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just execute this cell to have the proper functions imported\n",
    "# the cell must run correctly to be able to run the assignement\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as si\n",
    "from scipy import __version__ as scipy_version\n",
    "answers = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b929a",
   "metadata": {},
   "source": [
    "### Risk-Neutral Black-Scholes SDE\n",
    "\n",
    "In the risk-neutral measure, the Black-Scholes stochastic differential equation (SDE) for the stock price $ S_t $ is:\n",
    "\n",
    "$$\n",
    "dS_t = r S_t \\, dt + \\sigma S_t \\, dW_t\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ r $ is the risk-free interest rate,\n",
    "- $ \\sigma $ is the volatility of the stock,\n",
    "- $ W_t $ is a standard Brownian motion.\n",
    "\n",
    "---\n",
    "\n",
    "### SDE for $ \\ln(S_t) $\n",
    "\n",
    "Using Itô's Lemma, we can derive the SDE for $ \\ln(S_t) $. Let $ X_t = \\ln(S_t) $. Then:\n",
    "\n",
    "$$\n",
    "dX_t = d(\\ln(S_t)) = \\left( r - \\frac{1}{2} \\sigma^2 \\right) dt + \\sigma \\, dW_t\n",
    "$$\n",
    "\n",
    "This is a simpler SDE because it has no dependence on $ S_t $. The solution to this SDE is:\n",
    "\n",
    "$$\n",
    "X_t = X_0 + \\left( r - \\frac{1}{2} \\sigma^2 \\right) t + \\sigma W_t\n",
    "$$\n",
    "\n",
    "where $ X_0 = \\ln(S_0) $.\n",
    "\n",
    "---\n",
    "\n",
    "### Option Price $ C(T, K) $\n",
    "\n",
    "The price of a European call option with maturity $ T $ and strike $ K $ is given by:\n",
    "\n",
    "$$\n",
    "C(T, K) = \\mathbb{E} \\left[ e^{-rT} \\max(S_T - K, 0) \\right]\n",
    "$$\n",
    "\n",
    "Under the risk-neutral measure, $ S_T $ is log-normally distributed:\n",
    "\n",
    "$$\n",
    "S_T = S_0 \\exp \\left( \\left( r - \\frac{1}{2} \\sigma^2 \\right) T + \\sigma W_T \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Statistical Estimator $ \\hat{C}(T, K) $\n",
    "\n",
    "To estimate $ C(T, K) $ using Monte Carlo simulation, we can simulate $ N_{\\text{sim}} $ paths of $ \\ln(S_T(\\omega_i)) $ and compute the average discounted payoff. Here's how:\n",
    "\n",
    "1. **Simulate $ \\ln(S_T(\\omega_i)) $**:\n",
    "   - Generate $ N_{\\text{sim}} $ independent standard normal random deviates $ Z(\\omega_i) \\sim \\mathcal{N}(0, 1) $.\n",
    "   - For each $ Z(\\omega_i) $, compute:\n",
    "     $$\n",
    "     \\ln(S_T(\\omega_i)) = \\ln(S_0) + \\left( r - \\frac{1}{2} \\sigma^2 \\right) T + \\sigma \\sqrt{T} Z(\\omega_i)\n",
    "     $$\n",
    "\n",
    "2. **Compute $ S_T(\\omega_i) $**:\n",
    "   - Exponentiate to get the stock price at time $ T $:\n",
    "     $$\n",
    "     S_T(\\omega_i) = \\exp \\left( \\ln(S_T(\\omega_i)) \\right)\n",
    "     $$\n",
    "\n",
    "3. **Compute the Payoff**:\n",
    "   - For each $ S_T(\\omega_i) $, compute the payoff:\n",
    "     $$\n",
    "     \\text{Payoff}(\\omega_i) = \\max(S_T(\\omega_i) - K, 0)\n",
    "     $$\n",
    "\n",
    "4. **Estimate $ C(T, K) $**:\n",
    "   - Average the discounted payoffs:\n",
    "     $$\n",
    "     \\hat{C}(T, K) = e^{-rT} \\cdot \\frac{1}{N_{\\text{sim}}} \\sum_{i=1}^{N_{\\text{sim}}} \\text{Payoff}(\\omega_i)\n",
    "     $$\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_mc_call_price(S0, K, T, r, sigma, param):\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    # Step 1: Generate uniform random variables U\n",
    "    U = np.random.uniform(0, 1, param[\"N_sim\"])\n",
    "    # Step 2: Transform U into standard normal random variables Z using the inverse CDF\n",
    "    Z = si.norm.ppf(U)\n",
    "    # Step 2: Simulate ln(S_T(\\omega_i))\n",
    "    ln_ST = np.log(S0) + (r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z\n",
    "    # Step 3: Compute S_T(\\omega_i)\n",
    "    ST = np.exp(ln_ST)\n",
    "    # Step 4: Compute payoffs\n",
    "    payoffs = np.maximum(ST - K, 0)\n",
    "    # Step 5: Estimate C(T, K)\n",
    "    C_hat = np.exp(-r * T) * np.mean(payoffs)\n",
    "    return C_hat\n",
    "\n",
    "### Example usage\n",
    "S0 = 100  # Initial stock price\n",
    "K = 100   # Strike price\n",
    "T = 1     # Time to maturity (1 year)\n",
    "r = 0.05  # Risk-free rate\n",
    "sigma = 0.2  # Volatility\n",
    "N_sim = 100000  # Number of simulations\n",
    "C_hat = black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":N_sim})\n",
    "answers[\"call price estimator for 100000 mc steps is\"] = C_hat\n",
    "C_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed351b1a",
   "metadata": {},
   "source": [
    "### Black Scholes Closed-Form Formula \n",
    "$$\n",
    "C(T, K) = S_0 \\Phi(d_1) - K e^{-rT} \\Phi(d_2)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\Phi(\\cdot) $ is the cumulative distribution function (CDF) of the standard normal distribution,\n",
    "- $ d_1 $ and $ d_2 $ are given by:\n",
    "\n",
    "$$\n",
    "d_1 = \\frac{\\ln(S_0 / K) + (r + \\sigma^2 / 2) T}{\\sigma \\sqrt{T}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_2 = d_1 - \\sigma \\sqrt{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_call_price(S0, K, T, r, sigma):\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    # Calculate d1 and d2\n",
    "    d1 = (np.log(S0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    # Calculate the call option price\n",
    "    call_price = S0 * si.norm.cdf(d1) - K * np.exp(-r * T) * si.norm.cdf(d2)\n",
    "    return call_price\n",
    "\n",
    "C = black_scholes_call_price(S0, K, T, r, sigma)\n",
    "answers[\"exact BSM price that we try to approximate is\"] = C\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b49d1",
   "metadata": {},
   "source": [
    "### Convergence Study\n",
    "\n",
    "The performance of the estimator $\\hat{C}(T, K)$ can be compared to $C(T,K)$ using\n",
    "\n",
    "$$\n",
    "err = \\frac{|\\hat{C}(T, K)-C(T,K)|}{S_0}\n",
    "$$\n",
    "\n",
    "As $N_{sim}$ increases, we expect the estimator standard deviation to reduce with $1/\\sqrt{N_{sim}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims = (np.arange(5,300))**2\n",
    "err = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim})-C)/S0 for nsim in nsims]\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(err)))\n",
    "plt.xlabel(\"Nsim^1/2\")\n",
    "plt.ylabel(\"log10 of abs estimation error\")\n",
    "plt.title(\"relative error\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# relative error is np.log10(abs(Chat-C)/S0))\n",
    "answers[\"we need what Nsim at the minimum to have a 1e-2 precision\"] = 0 # approximate Nsim\n",
    "answers[\"we need what Nsim at the minimum to have a 1e-3 precision\"] = 0 # approximate Nsim\n",
    "answers[\"numerical precision of 1e-5 seems hard to get with this method\"] = \"yes/no\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4240c3",
   "metadata": {},
   "source": [
    "### Antithetic Sampling\n",
    "\n",
    "**Antithetic sampling** is a variance reduction technique used in Monte Carlo simulations. It involves generating pairs of negatively correlated random samples to reduce the overall variance of the estimator. When sampling from a uniform distribution $ U \\sim \\text{Uniform}(0, 1) $, its antithetic counterpart is $ 1 - U $. These pairs are then transformed into standard normal variables $ Z $ and $ -Z $ using the inverse CDF (e.g., $ Z = \\Phi^{-1}(U) $ and $ -Z = \\Phi^{-1}(1 - U) $). By averaging the results from $ Z $ and $ -Z $, the estimator's variance is reduced because the errors in the two samples tend to cancel each other out. This method is particularly effective for symmetric distributions and improves computational efficiency without requiring additional random samples.\n",
    "\n",
    "For a function $ f $ and uniform samples $ U_i $, the antithetic estimator is:\n",
    "\n",
    "$$\n",
    "\\hat{C}_{\\text{antithetic}} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(Z_i) + f(-Z_i)}{2},\n",
    "$$\n",
    "\n",
    "where $ Z_i = \\Phi^{-1}(U_i) $ and $ -Z_i = \\Phi^{-1}(1 - U_i) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_mc_call_price(S0, K, T, r, sigma, param):\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    # Step 1: Generate uniform random variables U\n",
    "    if param.get(\"antithetic\")==True:\n",
    "        U = np.random.uniform(0, 1, param[\"N_sim\"]//2)\n",
    "        U = np.hstack([U,1-U])\n",
    "    else:\n",
    "        U = np.random.uniform(0, 1, param[\"N_sim\"])\n",
    "    # Step 2: Transform U into standard normal random variables Z using the inverse CDF\n",
    "    Z = si.norm.ppf(U)\n",
    "    # Step 2: Simulate ln(S_T(\\omega_i))\n",
    "    ln_ST = np.log(S0) + (r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z\n",
    "    # Step 3: Compute S_T(\\omega_i)\n",
    "    ST = np.exp(ln_ST)\n",
    "    # Step 4: Compute payoffs\n",
    "    payoffs = np.maximum(ST - K, 0)\n",
    "    # Step 5: Estimate C(T, K)\n",
    "    C_hat = np.exp(-r * T) * np.mean(payoffs)\n",
    "    return C_hat\n",
    "\n",
    "nsims = (np.arange(5,300))**2\n",
    "err = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim})-C)/S0 for nsim in nsims]\n",
    "erranti = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim,\"antithetic\":True})-C)/S0 for nsim in nsims]\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(err)),label=\"standard\")\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(erranti)),label=\"antithetic\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Nsim^1/2\")\n",
    "plt.ylabel(\"log10 of abs estimation error\")\n",
    "plt.title(\"error\")\n",
    "plt.show()\n",
    "answers[\"is antithetic sampling better?\"] = \"yes/no\" \n",
    "answers[\"how much of an order of magnitude change does antithetic sampling give?\"] = 0 # this is 1 if error goes from 1e-3 to 1e-4\n",
    "answers[\"numerical precision of 1e-5 seems hard to get with antithetic\"] = \"yes/no\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc71413",
   "metadata": {},
   "source": [
    "### Low Descrepancy Pseudo-Random Sequence\n",
    "\n",
    "A **Sobol sequence** is a **low-discrepancy sequence** used in quasi-Monte Carlo methods for numerical integration and simulation. It generates points in a highly uniform manner across a multidimensional space, ensuring better coverage than pseudorandom numbers. Sobol sequences are deterministic and constructed using base-2 arithmetic, making them efficient and reproducible. They are particularly useful for reducing variance in Monte Carlo simulations, leading to faster convergence. Each point in the sequence depends on the previous ones, ensuring no clustering or gaps. Sobol sequences are widely used in finance, engineering, and computer graphics for their ability to provide accurate results with fewer samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_mc_call_price(S0, K, T, r, sigma, param):\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    # Step 1: Generate uniform random variables U\n",
    "    nsim = param[\"N_sim\"]//2 if param.get(\"antithetic\")==True else param[\"N_sim\"]\n",
    "    if param.get(\"sobol\")==True:\n",
    "        U = si.qmc.Sobol(d=1).random(nsim)\n",
    "    else:\n",
    "        U = np.random.uniform(0, 1, nsim)\n",
    "    if param.get(\"antithetic\")==True:\n",
    "        U = np.hstack([U,1-U])\n",
    "    # Step 2: Transform U into standard normal random variables Z using the inverse CDF\n",
    "    Z = si.norm.ppf(U)\n",
    "    # Step 2: Simulate ln(S_T(\\omega_i))\n",
    "    ln_ST = np.log(S0) + (r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z\n",
    "    # Step 3: Compute S_T(\\omega_i)\n",
    "    ST = np.exp(ln_ST)\n",
    "    # Step 4: Compute payoffs\n",
    "    payoffs = np.maximum(ST - K, 0)\n",
    "    # Step 5: Estimate C(T, K)\n",
    "    C_hat = np.exp(-r * T) * np.mean(payoffs)\n",
    "    return C_hat\n",
    "\n",
    "nsims = (np.arange(5,200))**2\n",
    "err = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim,\"sobol\":True})-C)/S0 for nsim in nsims]\n",
    "errantisobol = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim,\"sobol\":True,\"antithetic\":True})-C)/S0 for nsim in nsims]\n",
    "erranti = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim,\"sobol\":False,\"antithetic\":True})-C)/S0 for nsim in nsims]\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(err)),label=\"standard sobol\")\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(errantisobol)),label=\"antithetic sobol\")\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(erranti)),label=\"antithetic\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Nsim^1/2\")\n",
    "plt.ylabel(\"log10 of abs estimation error\")\n",
    "plt.title(\"error for sobol sequence\")\n",
    "plt.show()\n",
    "answers[\"is sobol better?\"] = \"yes/no\"\n",
    "answers[\"numerical precision of 1e-5 seems hard to get with sobol\"] = \"yes/no\"\n",
    "answers[\"does it look interesting to combine sobol and antithetic?\"] = \"yes/no\"\n",
    "answers[\"how much of an order of magnitude improvement in error do we get\"] = 0 # this would be 2 for going from 1e-6 to 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2185c2",
   "metadata": {},
   "source": [
    "### Checking the Numpy Gaussian Random Variable Generator\n",
    "The numpy library can generate gaussian random variables directly. \n",
    "\n",
    "How good is convergence with these?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_mc_call_price(S0, K, T, r, sigma, param):\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    # Step 1: Generate uniform random variables U\n",
    "    nsim = param[\"N_sim\"]//2 if param.get(\"antithetic\")==True else param[\"N_sim\"]\n",
    "    if param.get(\"numpy\")==True:\n",
    "        Z = np.random.normal(0, 1, nsim)\n",
    "    else:\n",
    "        if param.get(\"sobol\")==True:\n",
    "            U = si.qmc.Sobol(d=1).random(nsim)\n",
    "        else:\n",
    "            U = np.random.uniform(0, 1, nsim)\n",
    "        # Step 2: Transform U into standard normal random variables Z using the inverse CDF\n",
    "        Z = si.norm.ppf(U)\n",
    "    if param.get(\"antithetic\")==True:\n",
    "        Z = np.hstack([Z,-Z])\n",
    "    # Step 2: Simulate ln(S_T(\\omega_i))\n",
    "    ln_ST = np.log(S0) + (r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z\n",
    "    # Step 3: Compute S_T(\\omega_i)\n",
    "    ST = np.exp(ln_ST)\n",
    "    # Step 4: Compute payoffs\n",
    "    payoffs = np.maximum(ST - K, 0)\n",
    "    # Step 5: Estimate C(T, K)\n",
    "    C_hat = np.exp(-r * T) * np.mean(payoffs)\n",
    "    return C_hat\n",
    "\n",
    "err = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim,\"sobol\":True})-C)/S0 for nsim in nsims]\n",
    "errnumpy = [(black_scholes_mc_call_price(S0, K, T, r, sigma, {\"N_sim\":nsim,\"numpy\":True})-C)/S0 for nsim in nsims]\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(err)),label=\"standard sobol\")\n",
    "plt.plot(np.sqrt(nsims), np.log10(np.abs(errnumpy)),label=\"numpy gauss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Nsim^1/2\")\n",
    "plt.ylabel(\"log10 of abs estimation error\")\n",
    "plt.title(\"error for sobol sequence\")\n",
    "plt.show()\n",
    "answers[\"is sobol better than numpy guassian?\"] = \"yes/no\"\n",
    "answers[\"numerical precision of 1e-5 seems hard to get with numpy\"] = \"yes/no\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d0020c",
   "metadata": {},
   "source": [
    "\n",
    "### Black-Scholes-Merton (BSM) SDE for $ n $ Stocks\n",
    "\n",
    "For $ n $ stocks $ S^i_t $ ($ i = 1, \\dots, n $), the **risk-neutral BSM SDE** is:\n",
    "\n",
    "$$\n",
    "dS^i_t = r S^i_t \\, dt + \\sigma_i S^i_t \\, dW^i_t,\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ r $ is the risk-free rate,\n",
    "- $ \\sigma_i $ is the volatility of stock $ i $,\n",
    "- $ W^i_t $ is a standard Brownian motion for stock $ i $,\n",
    "- The Brownian motions are correlated: $ dW^i_t \\, dW^j_t = \\rho_{ij} \\, dt $, where $ \\rho_{ij} $ is the correlation between $ W^i_t $ and $ W^j_t $.\n",
    "\n",
    "---\n",
    "\n",
    "### SDE for $ \\ln(S^i_t) $\n",
    "\n",
    "Using Itô's Lemma, the SDE for $ \\ln(S^i_t) $ is:\n",
    "\n",
    "$$\n",
    "d\\ln(S^i_t) = \\left( r - \\frac{1}{2} \\sigma_i^2 \\right) dt + \\sigma_i \\, dW^i_t.\n",
    "$$\n",
    "\n",
    "Integrating this, we get:\n",
    "\n",
    "$$\n",
    "\\ln(S^i_T) = \\ln(S^i_0) + \\left( r - \\frac{1}{2} \\sigma_i^2 \\right) T + \\sigma_i W^i_T.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Covariance Matrix $ \\Sigma $ of $ \\ln(S^i_T) $\n",
    "\n",
    "The covariance matrix $ \\Sigma $ of $ \\ln(S^i_T) $ is an $ n \\times n $ matrix where:\n",
    "\n",
    "$$\n",
    "\\Sigma_{ij} = \\text{Cov}(\\ln(S^i_T), \\ln(S^j_T)) = \\sigma_i \\sigma_j \\rho_{ij} T.\n",
    "$$\n",
    "\n",
    "The diagonal elements are:\n",
    "\n",
    "$$\n",
    "\\Sigma_{ii} = \\text{Var}(\\ln(S^i_T)) = \\sigma_i^2 T.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Monte Carlo Estimator $ \\hat{P} $ for $ P = \\mathbb{E}[\\max(K - \\min_i(S^i_T), 0)] $\n",
    "\n",
    "To estimate the payoff $ P = \\mathbb{E}[\\max(K - \\min_i(S^i_T), 0)] $, we can use Monte Carlo simulation as follows:\n",
    "\n",
    "1. **Simulate Correlated Log-Normal Stock Prices**:\n",
    "   - Generate correlated Brownian motions $ W^i_T $ using the covariance matrix $ \\Sigma $.\n",
    "   - Compute $ \\ln(S^i_T) $ for each stock.\n",
    "   - Exponentiate to get $ S^i_T $.\n",
    "\n",
    "2. **Compute the Payoff**:\n",
    "   - For each simulation $ \\omega_j $, compute the minimum of the stock prices $ \\min_i(S^i_T(\\omega_j)) $.\n",
    "   - Compute the payoff $ \\max(K - \\min_i(S^i_T(\\omega_j)), 0) $.\n",
    "\n",
    "3. **Average the Payoffs**:\n",
    "   - The Monte Carlo estimator is the average of the payoffs across all simulations:\n",
    "\n",
    "$$\n",
    "\\hat{P} = \\frac{1}{N_{\\text{sim}}} \\sum_{j=1}^{N_{\\text{sim}}} \\max\\left(K - \\min_i(S^i_T(\\omega_j)), 0\\right).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Generating Correlated Normal Random Variables\n",
    "\n",
    "To generate correlated normal random variables $ Z $ with covariance matrix $ \\Sigma $, we use the **Cholesky decomposition** of $ \\Sigma $:\n",
    "\n",
    "1. **Cholesky Decomposition**:\n",
    "   - Decompose $ \\Sigma $ as $ \\Sigma = A A^\\top $, where $ A $ is a lower triangular matrix.\n",
    "\n",
    "2. **Generate IID Normal Random Variables**:\n",
    "   - Generate $ G \\sim \\mathcal{N}(0, I) $, where $ I $ is the identity matrix.\n",
    "\n",
    "3. **Compute Correlated Normal Random Variables**:\n",
    "   - Transform $ G $ using $ Z = A G $. The covariance of $ Z $ is $ \\Sigma $.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Covariance Matrix**:\n",
    "   - $ \\Sigma $ is computed using the outer product of volatilities and the correlation matrix.\n",
    "\n",
    "2. **Cholesky Decomposition**:\n",
    "   - The Cholesky factor $ A $ is computed using `scipy.linalg.cholesky`.\n",
    "\n",
    "3. **Random Variables**:\n",
    "   - Uniform random variables $ U $ are transformed into standard normal variables $ G $ using the inverse CDF (`norm.ppf`).\n",
    "   - Correlated normal variables $ Z $ are generated as $ Z = G A^\\top $.\n",
    "\n",
    "4. **Stock Prices**:\n",
    "   - Log stock prices $ \\ln(S_T) $ are simulated using the BSM formula.\n",
    "   - Stock prices $ S_T $ are obtained by exponentiating.\n",
    "\n",
    "5. **Payoff Calculation**:\n",
    "   - The minimum of the stock prices $ \\min_i(S^i_T) $ is computed for each simulation.\n",
    "   - The payoff $ \\max(K - \\min_i(S^i_T), 0) $ is averaged to get the Monte Carlo estimator $ \\hat{P} $.\n",
    "\n",
    "---\n",
    "\n",
    "### Formula for $ \\hat{P} $:\n",
    "\n",
    "The Monte Carlo estimator $ \\hat{P} $ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{P} = \\frac{1}{N_{sim}} \\sum_{j=1}^{N_{sim}} \\max\\left(K - \\min_i(S^i_T(\\omega_j)), 0\\right).\n",
    "$$\n",
    "\n",
    "This formula averages the payoffs across all simulations to estimate the expected value of the option payoff.\n",
    "\n",
    "Let me know if you need further clarification!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import cholesky\n",
    "\n",
    "def is_positive_semi_definite(matrix):\n",
    "    \"\"\"\n",
    "    Check if a matrix is positive semi-definite by verifying that all eigenvalues are non-negative.\n",
    "    \"\"\"\n",
    "    eigenvalues = np.linalg.eigvals(matrix)\n",
    "    return np.all(eigenvalues >= 0)\n",
    "\n",
    "def montecarlo_worstput(S0, sigma, corr, K, r, T, nsim):\n",
    "    n = len(S0)  # Number of stocks\n",
    "\n",
    "    # Build the correlation matrix rho\n",
    "    rho = np.eye(n)  # Identity matrix (1 on diagonal)\n",
    "    rho[np.triu_indices(n, k=1)] = corr  # Set upper triangular off-diagonal elements\n",
    "    rho[np.tril_indices(n, k=-1)] = corr  # Set lower triangular off-diagonal elements\n",
    "\n",
    "    # Covariance matrix Σ\n",
    "    Sigma = np.outer(sigma, sigma) * rho * T\n",
    "    if not is_positive_semi_definite(Sigma):\n",
    "        raise Exception(f\"ERR: montecarlo_worstput corr={corr} leads to non sdp covariance\")\n",
    "\n",
    "    # Cholesky decomposition of Σ\n",
    "    A = cholesky(Sigma, lower=True)\n",
    "\n",
    "    # Generate uniform random variables U with shape (nsim,n)\n",
    "    np.random.seed(42)  # You can use any integer value as the seed\n",
    "    U = np.random.uniform(0, 1, (nsim,n))\n",
    "\n",
    "    # Transform U to standard normal random variables G\n",
    "    G = si.norm.ppf(U)\n",
    "\n",
    "    # Generate correlated normal random variables Z\n",
    "    Z = G @ A.T\n",
    "\n",
    "    # Simulate log stock prices ln(S_T)\n",
    "    ln_ST = np.log(S0) + (r - 0.5 * sigma**2) * T + Z\n",
    "\n",
    "    # Compute stock prices S_T\n",
    "    ST = np.exp(ln_ST)\n",
    "\n",
    "    # Compute the minimum of the stock prices for each simulation\n",
    "    min_ST = np.min(ST, axis=1)\n",
    "\n",
    "    # Compute the payoff max(K - min_ST, 0)\n",
    "    payoffs = np.maximum(K - min_ST, 0)\n",
    "\n",
    "    # Monte Carlo estimator P_hat\n",
    "    P_hat = np.exp(-r * T) * np.mean(payoffs)\n",
    "    return P_hat\n",
    "\n",
    "# Parameters\n",
    "n = 3  # Number of stocks\n",
    "T = 1  # Time to maturity\n",
    "r = 0.05  # Risk-free rate\n",
    "sigma = np.array([0.2, 0.3, 0.25])  # Volatilities\n",
    "corr = 0.5  # Correlation coefficient (off-diagonal)\n",
    "K = 100  # Strike price\n",
    "S0 = np.array([100, 100, 100])  # Initial stock prices\n",
    "nsim = 100000  # Number of simulations\n",
    "\n",
    "# Run the Monte Carlo simulation\n",
    "P_hat = montecarlo_worstput(S0,sigma,corr,K,r,T,nsim)\n",
    "answers[\"worst off put price estimator for 100000 mc steps is\"] = P_hat\n",
    "P_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3210d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_hat = {}\n",
    "for nsim in np.arange(10,200)**2:\n",
    "    P_hat[nsim] = montecarlo_worstput(S0,sigma,corr,K,r,T,nsim)\n",
    "plt.plot(np.sqrt(list(P_hat.keys())),P_hat.values())\n",
    "plt.xlabel(\"Nsim^1/2\")\n",
    "plt.ylabel(\"estimator\")\n",
    "plt.title(\"price convergence for worst off put\")\n",
    "plt.show()\n",
    "answers[\"worst off put price estimator variance seems to dampen for sqrt(Nsim) greater than\"] = 0 # put recommended value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8877954",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_hat = {}\n",
    "for corr in np.linspace(-1,1,50):\n",
    "    try:\n",
    "        P_hat[corr] = montecarlo_worstput(S0,sigma,corr,K,r,T,nsim)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "plt.plot(P_hat.keys(),P_hat.values())\n",
    "plt.xlabel(\"corr\")\n",
    "plt.ylabel(\"MC Price\")\n",
    "plt.title(\"worst-off Put price\")\n",
    "plt.show()\n",
    "answers[\"how is worst-off put price impacted by correlation\"] = \"up/down\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to edit this cell to edit MYEMAIL and MYKEY. running this cell will submit your answers\n",
    "course = \"mafs5330\"\n",
    "# import config\n",
    "# config.createhash(answers,course)\n",
    "# MYEMAIL = config.profemail[course]\n",
    "# MYKEY = config.profapikey[course]\n",
    "# edit line below when ready to post the answer, http status_code for succesful submission is 200\n",
    "MYID  = 'rshao@connect.ust.hk' # <- EDIT email address that received api key from <mail.validation@mg.quantfinance.club>'\n",
    "MYKEY = '46bb4348b44334e3277327c46999c668bc7db49a02fae092d32348136f5f3ad5'\n",
    "import requests,json,time\n",
    "def post_answer(question, answer):\n",
    "    time.sleep(0.01)\n",
    "    questionhash = {\"call price estimator for 100000 mc steps is\": \"87d97f44f0a8764df28d4a7cd95dd7e9d4d698361cbe3ac0393749f556e03f7f\", \"exact BSM price that we try to approximate is\": \"461d0b79a9ca063afa397bc0a78aaefdf03bef0e9242a22d63ac027e34ab39dc\", \"we need what Nsim at the minimum to have a 1e-2 precision\": \"a6e4ac292681c5469c78e465eb783e4307a9d475ed5edd7b0cd3df0022ebeef4\", \"we need what Nsim at the minimum to have a 1e-3 precision\": \"641c511f77d70e9e68223becbbe3fe27c101549d97b664a35eac186c8ccf3208\", \"numerical precision of 1e-5 seems hard to get with this method\": \"e73d8180430cfe5a79e6ff2403ce0e2ce3f00c7c91d687bde923e469e0a2bd08\", \"is antithetic sampling better?\": \"fe64c006c4ab583d85c1a2b987c63ece9cc0625c9b7b0a087cf4e7ebb7b7d8ad\", \"how much of an order of magnitude change does antithetic sampling give?\": \"f47755597e3e3f33d0495833e481b6a09ab75e60170f3214026d26c3a52fab3f\", \"numerical precision of 1e-5 seems hard to get with antithetic\": \"656a69fc73d872ba43db7c5822a74e78e5932f9792e230f360f47a22ebf8f104\", \"is sobol better?\": \"fb2ad59e5625f15dfe779346226fddccf35f3c53177eef35a3697715a581d420\", \"numerical precision of 1e-5 seems hard to get with sobol\": \"5f33eaee60d0a8b6f507bfcf94517158ec427ac4bd167e8651932151d7541d86\", \"does it look interesting to combine sobol and antithetic?\": \"ae66c42fd17f34559445a1ca0edb3e9120f5d736b3c67a497588fb7180909c42\", \"how much of an order of magnitude improvement in error do we get\": \"2357eb8ef14072df0d86e994616ab3f3114a71d6d1067afa52d716dbb39450c1\", \"is sobol better than numpy guassian?\": \"9392ccc0eed161693a912f3528aeceeb1a17ac6f00cd5e5c5208e776e249bc21\", \"numerical precision of 1e-5 seems hard to get with numpy\": \"e9a9194564c5f3571eacd00deaa67c5206d470af163cb68eadc7f0a4e4536643\", \"worst off put price estimator for 100000 mc steps is\": \"c2b28106a1674f7e84692b77b8aaa4d30d8b66262d6abf627b6a840ba6f53d21\", \"worst off put price estimator variance seems to dampen for sqrt(Nsim) greater than\": \"3cbe451428197c2338ffed7f15de6dfc29ee8706ffbec9a78f1b5eb966ac9f37\", \"how is worst-off put price impacted by correlation\": \"4b01b7045a01754dc0b080899ed7cfb833d13aa647a18a562288ec28c6952c77\"}\n",
    "    return requests.post(f\"https://www.quantfinance.club/{course}\",data={'user':MYEMAIL,'mykey':MYKEY,'questionid':question,'answer':answer,'questionkey':questionhash[question]})\n",
    "nbAnswers = 17\n",
    "if len(answers)!=nbAnswers:\n",
    "    raise Exception(f\"There are {len(answers)} answers, should be {nbAnswers}. You can comment this check if you want to submit partial answers.\")\n",
    "for q,a in answers.items():\n",
    "    x = post_answer(q, a)\n",
    "    if x.status_code!=200:\n",
    "        if x.status_code==401:\n",
    "            raise Exception(\"API Key Authentication failed: please make sure the variables MYEMAIL and MYKEY are set\")\n",
    "        raise Exception(\"submission error with code:\",x.status_code)\n",
    "    else:\n",
    "        print(\"submitted answer to %s=%s\" % (q,str(a)))\n",
    "print(f\"check your latest submitted answers on:\\nhttps://www.quantfinance.club/{course}_myanswers?email={MYEMAIL}&apikey={MYKEY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f48df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd676a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
